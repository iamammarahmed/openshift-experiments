apiVersion: apps/v1
kind: Deployment
metadata:
  name: dwhtrans-catalog-schema-loader
  labels:
    app.kubernetes.io/name: dwhtrans-catalog
    app.kubernetes.io/part-of: dwhtrans-catalog
    app.kubernetes.io/component: schema-loader
    exp.openshift.io/area: hive-catalog
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: dwhtrans-catalog
      app.kubernetes.io/component: schema-loader
  template:
    metadata:
      labels:
        app.kubernetes.io/name: dwhtrans-catalog
        app.kubernetes.io/part-of: dwhtrans-catalog
        app.kubernetes.io/component: schema-loader
        exp.openshift.io/area: hive-catalog
    spec:
      serviceAccountName: dwhtrans-catalog-serviceaccount
      initContainers:
        - name: schema-sync
          image: amazon/aws-cli:2.15.34
          imagePullPolicy: IfNotPresent
          env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: dwhtrans-catalog-s3
                  key: accessKey
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: dwhtrans-catalog-s3
                  key: secretKey
            - name: AWS_DEFAULT_REGION
              valueFrom:
                secretKeyRef:
                  name: dwhtrans-catalog-s3
                  key: region
            - name: S3_ENDPOINT
              valueFrom:
                secretKeyRef:
                  name: dwhtrans-catalog-s3
                  key: endpoint
            - name: S3_BUCKET
              valueFrom:
                secretKeyRef:
                  name: dwhtrans-catalog-s3
                  key: bucket
            - name: SCHEMA_S3_PREFIX
              value: schemas/hive-ddl
          command:
            - /bin/bash
            - -c
            - |
              set -euo pipefail
              mkdir -p /schema
              if [[ -z "${SCHEMA_S3_PREFIX}" ]]; then
                echo "SCHEMA_S3_PREFIX must be set to a folder prefix within the bucket" >&2
                exit 1
              fi
              endpoint_url="${S3_ENDPOINT}"
              if [[ "${endpoint_url}" != http://* && "${endpoint_url}" != https://* ]]; then
                endpoint_url="https://${endpoint_url}"
              fi
              prefix="${SCHEMA_S3_PREFIX%/}/"
              echo "Looking up latest schema object under s3://${S3_BUCKET}/${prefix}" >&2
              latest_key="$(aws s3api list-objects-v2 \
                --bucket "${S3_BUCKET}" \
                --prefix "${prefix}" \
                --query 'sort_by(Contents, &LastModified)[-1].Key' \
                --output text \
                --endpoint-url "${endpoint_url}" || true)"
              if [[ -z "${latest_key}" || "${latest_key}" == "None" ]]; then
                echo "No schema files found in s3://${S3_BUCKET}/${prefix}" >&2
                exit 1
              fi
              object_name="${latest_key##*/}"
              echo "Copying ${latest_key} to /schema/${object_name}" >&2
              aws s3 cp \
                "s3://${S3_BUCKET}/${latest_key}" \
                "/schema/${object_name}" \
                --endpoint-url "${endpoint_url}"
              echo "${object_name}" > /schema/latest.txt
          volumeMounts:
            - name: schema-work
              mountPath: /schema
      containers:
        - name: ddl-runner
          image: apache/hive:3.1.3
          imagePullPolicy: IfNotPresent
          env:
            - name: HIVE_CONF_DIR
              value: /opt/hive/conf
            - name: SCHEMA_S3_PREFIX
              value: schemas/hive-ddl
          command:
            - /bin/bash
            - -c
            - |
              set -euo pipefail
              if [[ ! -s /schema/latest.txt ]]; then
                echo "latest.txt not found; ensure the schema-sync init container completed successfully" >&2
                exit 1
              fi
              latest_name="$(head -n1 /schema/latest.txt)"
              schema_path="/schema/${latest_name}"
              if [[ ! -f "${schema_path}" ]]; then
                echo "Expected schema artifact ${schema_path} is missing" >&2
                exit 1
              fi
              echo "Executing Hive DDL from ${schema_path}" >&2
              hive -f "${schema_path}"
              echo "Schema load complete; sleeping to keep container available for logs" >&2
              sleep infinity
          volumeMounts:
            - name: schema-work
              mountPath: /schema
            - name: hive-config
              mountPath: /opt/hive/conf/hive-site.xml
              subPath: hive-site.xml
            - name: hive-config
              mountPath: /opt/hadoop/conf/core-site.xml
              subPath: core-site.xml
          resources:
            requests:
              cpu: 250m
              memory: 1Gi
            limits:
              cpu: 1
              memory: 2Gi
      volumes:
        - name: schema-work
          persistentVolumeClaim:
            claimName: dwhtrans-catalog-schema-loader
        - name: hive-config
          configMap:
            name: dwhtrans-catalog-config
      restartPolicy: Always
